---
apiVersion: batch/v1
kind: Job
metadata:
  name: tensorflow
  labels:
    app: tensorflow
  namespace: user
spec:
  completions: 1
  parallelism: 1
  selector:
    matchLabels:
      app: tensorflow
  template:
    metadata:
      labels:
        app: tensorflow
      namespace: user
    spec:
      containers:
        - name: tensorflow
          image: kyechou/tensorflow:gpu-arch
          resources:
            requests:
              alpha.kubernetes.io/nvidia-gpu: 8
            limits:
              alpha.kubernetes.io/nvidia-gpu: 8
          env:
            - name: PATH
              value: "/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/nvidia/bin"
            - name: LD_LIBRARY_PATH
              value: "/nvidia/lib"
          command:
            - 'python'
          args:
            - '/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py'
            - '--local_parameter_device=gpu'
            - '--num_gpus=8'
            - '--batch_size=64'
            - '--model=vgg16'
            - '--variable_update=replicated'
            - '--use_nccl=True'
          volumeMounts:
            - mountPath: /benchmarks
              name: benchmarks
            - mountPath: /nvidia/bin
              name: nv-bin
            - mountPath: /nvidia/lib
              name: nv-lib
      volumes:
        - name: benchmarks
          nfs:
            server: '140.110.16.155'
            path: /benchmarks
            readOnly: true
        - name: nv-bin
          nfs:
            server: '140.110.16.155'
            path: /nvidia/bin
            readOnly: true
        - name: nv-lib
          nfs:
            server: '140.110.16.155'
            path: /nvidia/lib
            readOnly: true
      nodeSelector:
        beta.kubernetes.io/os: linux
        alpha.kubernetes.io/nvidia-gpu-name: Tesla-P100-SXM2-16GB
        #alpha.kubernetes.io/nvidia-gpu-name: Tesla-P100-PCIE-12GB
      restartPolicy: Never
